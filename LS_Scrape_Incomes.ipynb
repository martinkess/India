{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cand = \"http://myneta.info/ls2014/index.php?action=summary&subAction=candidates_analyzed&sort=candidate#summary\"\n",
    "winners_crim = \"http://myneta.info/ls2014/index.php?action=summary&subAction=winner_crime&sort=candidate#summary\"\n",
    "source=requests.get(all_cand) # Modify here: winners works with smaller sample, all_cand with the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree= BeautifulSoup(source.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Total candidates analyzed by NEW:Loksabha 2014 Election</title>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_links = tree.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr><td>11</td><td><a href=\"candidate.php?candidate_id=1105\">A Prasad</a><b></b></td><td>KOLAR</td>\n",
      "<td>IND</td><td align=\"center\" style=\"\">0</td><td>10th Pass</td>\n",
      "<td align=\"right\">Rs 8,40,000<br><span style=\"color:black;font-size:70%;text-decoration:none;white-space:nowrap\"> ~ 8 Lacs+</span></br></td><td align=\"right\">Rs 0<br><span style=\"color:black;font-size:70%;text-decoration:none;white-space:nowrap\"> ~ </span> </br></td></tr>, <tr><td>12</td><td><a href=\"candidate.php?candidate_id=340\">A Sampath</a><b></b></td><td>ATTINGAL</td>\n",
      "<td>CPI(M)</td><td align=\"center\" style=\"\"><span style=\"color:red;font-weight:bold;font-size:150%\">1</span></td><td>Doctorate</td>\n",
      "<td align=\"right\">Rs 1,77,91,149<br><span style=\"color:black;font-size:70%;text-decoration:none;white-space:nowrap\"> ~ 1 Crore+</span></br></td><td align=\"right\">Rs 14,21,392<br><span style=\"color:black;font-size:70%;text-decoration:none;white-space:nowrap\"> ~ 14 Lacs+</span> </br></td></tr>, <tr><td>13</td><td><a href=\"candidate.php?candidate_id=7501\">A Thavamani</a><b></b></td><td>MADURAI</td>\n",
      "<td>BSP</td><td align=\"center\" style=\"\">0</td><td>Illiterate</td>\n",
      "<td align=\"right\">Rs 51,000<br><span style=\"color:black;font-size:70%;text-decoration:none;white-space:nowrap\"> ~ 51 Thou+</span></br></td><td align=\"right\">Rs 0<br><span style=\"color:black;font-size:70%;text-decoration:none;white-space:nowrap\"> ~ </span> </br></td></tr>]\n"
     ]
    }
   ],
   "source": [
    "table_pol = tree.findAll('table')[2]\n",
    "rows = table_pol.findAll(\"tr\")[2:]\n",
    "print rows[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We build one dictionary per candidate #\n",
    "# We give each candidates to idenfiers: its order in the list and its url address\n",
    "\n",
    "def id2(r):\n",
    "    url_string = str(r.find(\"a\").get(\"href\"))\n",
    "    id2 = int(re.search(r'\\d+', url_string).group())\n",
    "    return id2\n",
    "\n",
    "def c_link(r):\n",
    "    return r.find(\"a\").get(\"href\")\n",
    "def name(r):\n",
    "    return r.find(\"a\").get_text()\n",
    "def cols(r):\n",
    "    return r.findAll(\"td\")\n",
    "def assets(r):\n",
    "    col = cols(r)\n",
    "    ass1 = col[6].get_text().split(\"~\")[0].encode('ascii', 'ignore').replace(\"Rs\",\"\").replace(\",\",\"\")\n",
    "    if ass1 == \"Nil\":\n",
    "        ass2 = 0\n",
    "    else:\n",
    "        ass2=int(ass1)\n",
    "    return ass2\n",
    "\n",
    "def liab(r):\n",
    "    col = cols(r)\n",
    "    liab1 = col[7].get_text().split(\"~\")[0].encode('ascii', 'ignore').replace(\"Rs\",\"\").replace(\",\",\"\")\n",
    "    if liab1 == \"Nil\":\n",
    "        liab2 = 0\n",
    "    else:\n",
    "        liab2 = int(liab1)\n",
    "    return liab2\n",
    "\n",
    "info_candidate = lambda r: [int(cols(r)[0].get_text()),id2(r), r.find(\"a\").get(\"href\"),r.find(\"a\").get_text(),\n",
    "                            cols(r)[2].get_text(),cols(r)[3].get_text(),cols(r)[5].get_text(),\n",
    "                            int(cols(r)[4].get_text()),assets(r), liab(r)]\n",
    "\n",
    "title = ['id','id2','url','name','district','party','education','nr_crime','assets','liabilities']\n",
    "dict_candidates = [dict(zip(title,info_candidate(r))) for r in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assets': 154566136,\n",
       "  'district': u'NAWADA',\n",
       "  'education': u'Post Graduate',\n",
       "  'id': 1,\n",
       "  'id2': 148,\n",
       "  'liabilities': 2604969,\n",
       "  'name': u'Kaushal Yadav',\n",
       "  'nr_crime': 8,\n",
       "  'party': u'JD(U)',\n",
       "  'url': u'candidate.php?candidate_id=148'},\n",
       " {'assets': 2191523,\n",
       "  'district': u'AZAMGARH',\n",
       "  'education': u'Others',\n",
       "  'id': 2,\n",
       "  'id2': 9496,\n",
       "  'liabilities': 0,\n",
       "  'name': u'M. Aamir Rashadi',\n",
       "  'nr_crime': 1,\n",
       "  'party': u'Rashtriya Ulama Council',\n",
       "  'url': u'candidate.php?candidate_id=9496'},\n",
       " {'assets': 306023,\n",
       "  'district': u'MAHARAJGANJ',\n",
       "  'education': u'Graduate Professional',\n",
       "  'id': 3,\n",
       "  'id2': 9706,\n",
       "  'liabilities': 0,\n",
       "  'name': u'Rakesh Kumar Giri',\n",
       "  'nr_crime': 0,\n",
       "  'party': u'IND',\n",
       "  'url': u'candidate.php?candidate_id=9706'},\n",
       " {'assets': 3630000,\n",
       "  'district': u'CHENNAI SOUTH',\n",
       "  'education': u'8th Pass',\n",
       "  'id': 4,\n",
       "  'id2': 6912,\n",
       "  'liabilities': 850000,\n",
       "  'name': u'(Kuppal)G.Devadoss',\n",
       "  'nr_crime': 0,\n",
       "  'party': u'IND',\n",
       "  'url': u'candidate.php?candidate_id=6912'},\n",
       " {'assets': 44357368,\n",
       "  'district': u'GARHWAL',\n",
       "  'education': u'Graduate Professional',\n",
       "  'id': 5,\n",
       "  'id2': 74,\n",
       "  'liabilities': 0,\n",
       "  'name': u'(Maj Gen (Retd.) ) Bhuwan Chandra Khanduri (Avsm)',\n",
       "  'nr_crime': 0,\n",
       "  'party': u'BJP',\n",
       "  'url': u'candidate.php?candidate_id=74'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_candidates)\n",
    "dict_candidates[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id2</th>\n",
       "      <th>name</th>\n",
       "      <th>district</th>\n",
       "      <th>party</th>\n",
       "      <th>education</th>\n",
       "      <th>assets</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>nr_crime</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>611</td>\n",
       "      <td>Nandan Nilekani</td>\n",
       "      <td>BANGALORE SOUTH</td>\n",
       "      <td>INC</td>\n",
       "      <td>Graduate Professional</td>\n",
       "      <td>77102957219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>candidate.php?candidate_id=611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6782</th>\n",
       "      <td>9403</td>\n",
       "      <td>Shamali Das</td>\n",
       "      <td>KOLKATA DAKSHIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>8th Pass</td>\n",
       "      <td>20000060000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>candidate.php?candidate_id=9403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>9378</td>\n",
       "      <td>Shamali Das</td>\n",
       "      <td>JADAVPUR</td>\n",
       "      <td>IND</td>\n",
       "      <td>8th Pass</td>\n",
       "      <td>20000060000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>candidate.php?candidate_id=9378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2677</td>\n",
       "      <td>Anil Kumar Sharma</td>\n",
       "      <td>JAHANABAD</td>\n",
       "      <td>JD(U)</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>8498803720</td>\n",
       "      <td>1095393904</td>\n",
       "      <td>1</td>\n",
       "      <td>candidate.php?candidate_id=2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>8183</td>\n",
       "      <td>Jayadev Galla</td>\n",
       "      <td>GUNTUR</td>\n",
       "      <td>TDP</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>6830581361</td>\n",
       "      <td>202334283</td>\n",
       "      <td>0</td>\n",
       "      <td>candidate.php?candidate_id=8183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id2               name          district  party              education  \\\n",
       "4522   611    Nandan Nilekani   BANGALORE SOUTH    INC  Graduate Professional   \n",
       "6782  9403        Shamali Das  KOLKATA DAKSHIN     IND               8th Pass   \n",
       "6781  9378        Shamali Das          JADAVPUR    IND               8th Pass   \n",
       "433   2677  Anil Kumar Sharma         JAHANABAD  JD(U)              Doctorate   \n",
       "2846  8183      Jayadev Galla            GUNTUR    TDP               Graduate   \n",
       "\n",
       "           assets  liabilities  nr_crime                              url  \n",
       "4522  77102957219            0         0   candidate.php?candidate_id=611  \n",
       "6782  20000060000            0         0  candidate.php?candidate_id=9403  \n",
       "6781  20000060000            0         0  candidate.php?candidate_id=9378  \n",
       "433    8498803720   1095393904         1  candidate.php?candidate_id=2677  \n",
       "2846   6830581361    202334283         0  candidate.php?candidate_id=8183  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create a really big dictionary which stores url and page for each candidate\n",
    "# Work in progress...\n",
    "# First transform the thing into a dataframe\n",
    "\n",
    "df_pol = pd.DataFrame(dict_candidates)\n",
    "order_cols = ['id2','name','district','party','education','assets','liabilities','nr_crime','url']\n",
    "df_pol = df_pol[order_cols].sort(['assets'],ascending=0)\n",
    "\n",
    "df_small=df_pol[[\"id2\",\"url\"]][0:3] # I use df_small to test the code before running it on 8400 candidates!\n",
    "df_small\n",
    "df_pol.head()\n",
    "\n",
    "#Note already that the same guy can be candidate at 2 districts #\n",
    "# Might be a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urlcache={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    # Check if URL has already been visited.\n",
    "    if (url not in urlcache) or (urlcache[url]==1) or (urlcache[url]==2):\n",
    "        time.sleep(1)\n",
    "        steps = len(urlcache)\n",
    "        if 100*int(steps/100)==steps:\n",
    "            print steps # This counter tells us how many links were downloaded at every 100 mark\n",
    "        # try/except blocks are used whenever the code could generate an exception (e.g. division by zero).\n",
    "        # In this case we don't know if the page really exists, or even if it does, if we'll be able to reach it.\n",
    "        try:\n",
    "            r = requests.get(\"http://myneta.info/ls2014/%s\" % url)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "                urlcache[url] = r.text\n",
    "            else:\n",
    "                urlcache[url] = 1\n",
    "        except:\n",
    "            urlcache[url] = 2\n",
    "    return urlcache[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'urlcache' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-893c9dcedc6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_pol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This is a very long call (~4.5 hours on full dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m                               \u001b[1;31m# I am saving it in order to run it only once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mkkes_000\\Anaconda\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2060\u001b[1;33m         \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2061\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas\\lib.c:58435)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-b98a48979740>\u001b[0m in \u001b[0;36mget_page\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Check if URL has already been visited.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murlcache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murlcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murlcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'urlcache' is not defined"
     ]
    }
   ],
   "source": [
    "#df_pol[\"url\"].apply(get_page) # This is a very long call (~4.5 hours on full dataset)\n",
    "                              # I am saving it in order to run it only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print np.sum([(urlcache[k]==1) or (urlcache[k]==2) for k in urlcache])# no one or 0's\n",
    "print len(df_pol.url.unique())==len(urlcache)#we got all of the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open(\"tempdata/polinfo.json\",\"w\") as fd:\n",
    "#    json.dump(urlcache, fd)\n",
    "#del urlcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tempdata/polinfo.json\") as json_file:\n",
    "    pol_pages = json.load(json_file) # Next iterations will start from here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://myneta.info/ls2014/candidate.php?candidate_id=4792\n"
     ]
    }
   ],
   "source": [
    "# Now each candidate has an url - so later we  will parse each of their pages and scrape them#\n",
    "#But first let's look how the page looks like for a few individual candidates\n",
    "pages_list = [pol_pages[x] for x in df_pol['url'][0:10]] # List of 10 that we can start looking at\n",
    "\n",
    "i = 3\n",
    "url_candidate = pol_pages.keys()[i]\n",
    "full_url = \"http://myneta.info/ls2014/\" + url_candidate\n",
    "page_candidate = pol_pages.values()[i]\n",
    "c_soup = BeautifulSoup(page_candidate,\"html.parser\")\n",
    "print full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JYOTI SUKHLAL GORE  \n",
      " works as a: Labour . \n",
      " Profession of spouse: Labour and 5 thousand Monthly Income . \n",
      " Address:              Village Kasel Teh. Rajpur, Dist. Badwani , in district:  \n",
      "        KHARGONE  (MADHYA PRADESH)\n",
      "         for party: CPI\n",
      "  The dude is 34 years old\n",
      "\n",
      " \n",
      "8\n",
      "<table><tr><td>Not Given</td></tr></table>\n"
     ]
    }
   ],
   "source": [
    "#### Personal info #########\n",
    "\n",
    "personal = c_soup.findAll(attrs={\"class\": \"grid_3 alpha\"})[0]\n",
    "full_name = personal.find(\"h2\").get_text()\n",
    "district1 = personal.find(\"h5\").get_text()\n",
    "grid2 = personal.findAll(attrs={\"class\":\"grid_2 alpha\"})\n",
    "party_full = grid2[0].get_text().split(\":\")[1]\n",
    "age = int(grid2[2].get_text().split(\":\")[1])\n",
    "address = grid2[3].get_text().split(\":\")[1].split(\"\\n\")[1] # Careful this one changes\n",
    "self_profession = personal.find(\"p\").get_text().split('\\n')[0].split(\":\")[1]\n",
    "spouse_profession = personal.find(\"p\").get_text().split('\\n')[1].split(\":\")[1]\n",
    "print full_name, \"\\n works as a:\", self_profession, \". \\n Profession of spouse:\", spouse_profession, \". \\n Address: \",\n",
    "print address, \", in district: \", district1, \"for party:\", party_full, \"The dude is\", age, \"years old\"\n",
    "\n",
    "########## Assets  & Criminality ###########\n",
    "# Ok let's get serious and find his assets and criminal activity\n",
    "all_tables = c_soup.findAll(\"table\")\n",
    "print \"\\n \\n\" , len(all_tables)\n",
    "table_inc = all_tables[0]\n",
    "table_crim = all_tables[1]\n",
    "table_assets1 = all_tables[2]\n",
    "table_assets2 = all_tables[3]\n",
    "table_liab = all_tables[4]\n",
    "print table_inc\n",
    "# That does not really work: some have a table for criminal activities, others not\n",
    "# So we need more work to know exactly how to have the right table correspond to the right thing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## This code allows to get income levels of politicians and their relative #######\n",
    "######## There a few errors that remain (some pages do not go through - despite seeming valid) ######\n",
    "####### But possible to correct.\n",
    "\n",
    "cleaner = lambda e: int(re.findall('\\d+', e.replace(',', '').split(\" ~ \")[0])[0])\n",
    "income_cols = [\"Relation\",\"PAN\",\"Year\",\"Income\"]\n",
    "def income_table(candidate_id):\n",
    "    page_candidate = pol_pages[candidate_id]\n",
    "    c_soup = BeautifulSoup(page_candidate,\"html.parser\")\n",
    "    table_titles =[x.get_text().strip() for x in c_soup.findAll(\"h3\")]\n",
    "    tables = [x.find_next() for x in c_soup.findAll(\"h3\")]\n",
    "    dict_tab = dict(zip(table_titles,tables))\n",
    "    income_tab = dict_tab['Details of PAN and status of Income Tax return']\n",
    "    income_rows = income_tab.find_all(\"tr\")\n",
    "    dict_income = {}\n",
    "    df_inc = pd.DataFrame([])\n",
    "    if income_cols==[]:\n",
    "        dict_income = {'HH':{\"Year\":np.nan,\"PAN\":\"N\",\"Relation\":np.nan,\"Income\":np.nan}}\n",
    "    else:\n",
    "        for r in income_rows[1:]:\n",
    "            list_items = [x.get_text() for x in r.findAll(\"td\")]\n",
    "            if len(list_items)==4 and list_items[3]!=\"Nil\":\n",
    "                list_items[3] = cleaner(list_items[3])\n",
    "            if len(list_items)==4 and list_items[3]==\"Nil\":\n",
    "                list_items[3] = 0\n",
    "            dict_income[list_items[0]] = dict(zip(income_cols,list_items))\n",
    "        df_inc = df_inc.from_dict(dict_income,orient = \"index\")\n",
    "    try:\n",
    "        df_inc = df_inc[df_inc.PAN==\"Y\"]\n",
    "        HHinc = np.sum(df_inc['Income'])\n",
    "        HHDeclarations = np.count_nonzero(df_inc['PAN'])\n",
    "        self_income = dict_income['self']['Income']\n",
    "        self_declare = dict_income['self']['PAN']\n",
    "    except AttributeError:\n",
    "        df_inc=df_inc\n",
    "        HHinc = np.nan\n",
    "        HHDeclarations = 0\n",
    "        self_income = np.nan\n",
    "        self_declare = np.nan\n",
    "    newdict = {'self_inc':self_income,'self_declare':self_declare,'HHinc':HHinc,\"HHDeclarations\":HHDeclarations}\n",
    "    return newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HHDeclarations': 2,\n",
       " 'HHinc': 1371909L,\n",
       " 'self_declare': u'Y',\n",
       " 'self_inc': 725254}"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_table(pol_pages.keys()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 100 200 300 candidate.php?candidate_id=6112\n",
      "400 500 600 candidate.php?candidate_id=2923\n",
      "700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 candidate.php?candidate_id=8068\n",
      "2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 candidate.php?candidate_id=1469\n",
      "3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 candidate.php?candidate_id=5058\n",
      "5100 5200 5300 5400 5500 candidate.php?candidate_id=5390\n",
      "5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 candidate.php?candidate_id=4001\n",
      "8000 8100 8200\n"
     ]
    }
   ],
   "source": [
    "counterror = 0\n",
    "dict_allinc = {}\n",
    "for k,cid in enumerate(pol_pages.keys()):\n",
    "    try:\n",
    "        dict_allinc[cid] = income_table(cid)\n",
    "    except TypeError:\n",
    "        counterror = counterror+1\n",
    "        print cid\n",
    "    if k%100==0:\n",
    "        print k,\n",
    "    print counterror\n",
    "d_inc_HH = d_inc_fin.from_dict(dict_allinc,orient = \"index\") #d_inc_HH associates income to all candidates\n",
    "                                                             # as well as for the whole family\n",
    "                                                             # and the number of declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_inc_HH.to_csv(\"C:\\Users\\mkkes_000\\Dropbox\\Indiastuff\\incomes.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
